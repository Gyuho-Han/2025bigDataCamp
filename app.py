# app.py
import streamlit as st
import os, json, requests
from dotenv import load_dotenv

# LangChain / OpenAI imports
from langchain_core.documents import Document
from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder
from langchain_core.tools import tool
from langchain.agents import create_tool_calling_agent, AgentExecutor
from langchain_openai import AzureChatOpenAI, AzureOpenAIEmbeddings
from langchain.vectorstores import Chroma
from langchain.retrievers import BM25Retriever, EnsembleRetriever, ContextualCompressionRetriever
from langchain.retrievers.document_compressors import LLMListwiseRerank
from langchain_text_splitters import RecursiveCharacterTextSplitter

# 1) í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# 2) JSON â†’ Document ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
@st.cache_data(show_spinner=False)
def load_documents(path="seoul_tour_clean.json"):
    with open(path, "r", encoding="utf-8") as f:
        raw = json.load(f)
    docs = []
    for item in raw:
        content = f"{item['ëª…ì¹­']}\n{item.get('ê°œìš”','')}\n{item.get('ìƒì„¸ì •ë³´','')}"
        metadata = {k: item.get(k, "") for k in ["ì£¼ì†Œ","ë¬¸ì˜","ì‰¬ëŠ”ë‚ ","ì´ìš©ì‹œê°„","ì£¼ì°¨ì‹œì„¤","ëª…ì¹­"]}
        docs.append(Document(page_content=content.strip(), metadata=metadata))
    return docs

# 3) VectorStore ì´ˆê¸°í™” (_docs ì–¸ë”ë°” ì²˜ë¦¬)
@st.cache_resource(show_spinner=False)
def init_vectorstore(_docs):
    splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(
        model_name="gpt-4o-mini", chunk_size=250, chunk_overlap=25
    )
    chunks = splitter.split_documents(_docs)
    embed = AzureOpenAIEmbeddings(model="text-embedding-3-small")
    db = Chroma.from_documents(
        documents=chunks,
        embedding=embed,
        persist_directory="./chroma_db"
    )
    db.persist()
    return db

# 4) Hybrid Retriever ì´ˆê¸°í™” (_docs, _vector_db ì–¸ë”ë°” ì²˜ë¦¬)
@st.cache_resource(show_spinner=False)
def init_retriever(_docs, _vector_db):
    bm25 = BM25Retriever.from_documents(_docs)
    bm25.k = 15
    vect = _vector_db.as_retriever(search_kwargs={"k": 15})
    return EnsembleRetriever(retrievers=[bm25, vect], weights=[0.5, 0.5])

# 5) Reranking Retriever ì´ˆê¸°í™” (_hybrid)
@st.cache_resource(show_spinner=False)
def init_rerank_retriever(_hybrid):
    # ì¬ìˆœìœ„ìš© LLM (ì•½ê°„ ë†’ì€ ì˜¨ë„)
    llm_rerank = AzureChatOpenAI(model="gpt-4o-mini", temperature=0.7)
    re_ranker = LLMListwiseRerank.from_llm(
        llm=llm_rerank, top_n=10, verbose=True
    )
    return ContextualCompressionRetriever(
        base_compressor=re_ranker,
        base_retriever=_hybrid
    )

# 6) ë‚ ì”¨ ë„êµ¬
@tool
def get_weather() -> str:
    """ì„œìš¸ í˜„ì¬ ë‚ ì”¨ì™€ ê°•ìˆ˜ ì—¬ë¶€ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    key = os.getenv("OPENWEATHER_API_KEY")
    if not key:
        return "ERROR: OPENWEATHER_API_KEY missing"
    data = requests.get(
        f"http://api.openweathermap.org/data/2.5/weather?"
        f"q=Seoul&appid={key}&units=metric&lang=kr"
    ).json()
    desc = data["weather"][0]["description"]
    temp = data["main"]["temp"]
    rain = "â˜”ï¸ ë¹„ ì˜¤ëŠ” ì¤‘" if "Rain" in [w["main"] for w in data["weather"]] else "â˜€ï¸ ë¹„ ì•ˆ ì˜´"
    return json.dumps({"ë‚ ì”¨": desc, "ê¸°ì˜¨": f"{temp}Â°C", "ê°•ìˆ˜": rain}, ensure_ascii=False)

# 7) RAG+Rerank ê²€ìƒ‰ ë„êµ¬
@tool
def search_tour_place(query: str) -> str:
    """ì§ˆë¬¸ì— ë§ëŠ” ì„œìš¸ ê´€ê´‘ì§€ ì²­í¬ë¥¼ reranking í›„ ë°˜í™˜í•©ë‹ˆë‹¤."""
    docs = st.session_state.rerank_retriever.invoke(query)
    return "\n\n".join(d.page_content for d in docs)

# 8) AgentExecutor ì´ˆê¸°í™” (ì›ë³¸ ìƒì„¸ í”„ë¡¬í”„íŠ¸ í¬í•¨)
@st.cache_resource(show_spinner=False)
def init_agent():
    prompt = ChatPromptTemplate.from_messages([
        ("system", """
ë‹¹ì‹ ì€ ì„œìš¸ í† ë°•ì´ ê´€ê´‘ ì „ë¬¸ê°€ AIì…ë‹ˆë‹¤. ë„êµ¬ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•˜ì—¬ ì‚¬ìš©ìì˜ ìš”ì²­ì„ í•´ê²°í•˜ì„¸ìš”.  
ê°€ëŠ¥í•œ í•œ ì •í™•í•˜ê³  ê°„ê²°í•˜ê²Œ ë‹µí•˜ë©°, ì§ˆë¬¸ì´ ëª…í™•í•˜ì§€ ì•Šë‹¤ë©´ ì •ì¤‘íˆ ë˜ë¬»ìŠµë‹ˆë‹¤.  
í•­ìƒ ë„êµ¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‹µí•˜ì„¸ìš”. ë‚ ì”¨ê°€ ì¢‹ë‹¤ë©´ ì•¼ì™¸ë¡œ, ë‚ ì”¨ê°€ ì¢‹ì§€ ì•Šìœ¼ë©´ ì‹¤ë‚´ë¡œ ì¶”ì²œí•´ì£¼ì„¸ìš”.  
í˜„ì¬ ì„œìš¸ì˜ ë‚ ì”¨ë„ ì„¤ëª…í•´ì£¼ì„¸ìš”. toolì˜ ì •ë³´ë¥¼ ì¬êµ¬ì„±í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.

[ì§€ì¹¨]
- ì»¨í…ìŠ¤íŠ¸ì— ìˆëŠ” ì •ë³´ë§Œì„ ì‚¬ìš©í•˜ì—¬ ë‹µë³€í•  ê²ƒ  
- ì™¸ë¶€ ì§€ì‹ì´ë‚˜ ì •ë³´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ ê²ƒ  
- ì§ˆë¬¸ì´ ë¶ˆëª…í™•í•˜ë©´ ì •ì¤‘í•˜ê²Œ ë˜ë¬»ìŠµë‹ˆë‹¤.  
- ë„êµ¬ ì‚¬ìš© ê²°ê³¼ëŠ” ë³µë¶™í•˜ì§€ ë§ê³ , ìì—°ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ìœ¼ë¡œ ì¬êµ¬ì„±í•˜ì„¸ìš”.  
- ì¶”ì²œ ì¥ì†ŒëŠ” ì •í™•í•œ ëª…ì¹­ê³¼ í•¨ê»˜ ì„¤ëª…í•©ë‹ˆë‹¤.  
- ì¶”ì²œ ì´ìœ ì™€ ì„ ì • ê¸°ì¤€ì„ ëª…í™•íˆ ë°íˆì„¸ìš”. (ì˜ˆ: ì‹¤ì™¸ í™œë™, ì—­ì‚¬ì  ê°€ì¹˜, ê°€ì¡± ë‹¨ìœ„ ë“±)  
- ë‚ ì”¨ë¥¼ ê³ ë ¤í•´ì„œ ì¥ì†Œë¥¼ ì„ ì •í•˜ì‹œì˜¤.  
- ì¥ì†ŒëŠ” 5ê³³ ì„ ì •í•˜ì‹œì˜¤  
- ì»¨í…ìŠ¤íŠ¸ì—ì„œ ë‹µì„ ì°¾ì„ ìˆ˜ ì—†ëŠ” ê²½ìš° "ì£„ì†¡í•˜ì§€ë§Œ ê·¸ëŸ° ì¥ì†ŒëŠ” ì„œìš¸ì— ì—†ëŠ” ê²ƒ ê°™ìŠµë‹ˆë‹¤."ë¼ê³  ì‘ë‹µí•  ê²ƒ  
- ë‹µë³€ì€ ë…¼ë¦¬ì ì´ê³  êµ¬ì¡°í™”ëœ í˜•íƒœë¡œ ì œê³µí•  ê²ƒ  
- ë‹µë³€ì€ í•œêµ­ì–´ë¥¼ ì‚¬ìš©í•  ê²ƒ  
- ì„œìš¸ì— ì˜¤ë˜ì‚° ì‚¬ëŒì´ ì§€ë°©ì—ì„œ ì˜¬ë¼ì˜¨ ì‚¬ëŒì—ê²Œ ì—¬í–‰ì§€ë¥¼ ì¶”ì²œí•´ì£¼ëŠ” ëŠë‚Œìœ¼ë¡œ ëŒ€ë‹µí•  ê²ƒ  
"""),
        ("user", "{input}"),
        MessagesPlaceholder(variable_name="agent_scratchpad")
    ])
    llm = AzureChatOpenAI(model="gpt-4.1", temperature=0)
    tools = [get_weather, search_tour_place]
    agent = create_tool_calling_agent(llm=llm, tools=tools, prompt=prompt)
    return AgentExecutor(agent=agent, tools=tools, verbose=False)

# â€”â€” Streamlit ì•± ì‹œì‘ â€”â€” 
st.set_page_config(page_title="ì„œìš¸ ê´€ê´‘ì§€ ì¶”ì²œ AI", page_icon="ğŸ—ºï¸")
st.title("ğŸ—ºï¸ ì„œìš¸ ê´€ê´‘ì§€ ì¶”ì²œ AI")

# ë¦¬ì†ŒìŠ¤ ì´ˆê¸°í™”
docs = load_documents()
vector_db = init_vectorstore(docs)
st.session_state.hybrid_retriever = init_retriever(docs, vector_db)
st.session_state.rerank_retriever = init_rerank_retriever(st.session_state.hybrid_retriever)
agent_executor = init_agent()

# ì‚¬ìš©ì ì…ë ¥ UI
query = st.text_input(
    "ì—¬í–‰ ëª©ì /ìƒí™©ì„ ì…ë ¥í•˜ì„¸ìš”", 
    placeholder="ì˜ˆ: ë¹„ ì˜¤ëŠ” ë‚  ê°€ì¡±ê³¼ ê°ˆë§Œí•œ ê³³ ì¶”ì²œí•´ì¤˜"
)

if st.button("ì¶”ì²œë°›ê¸°") and query:
    with st.spinner("ì¶”ì²œ ìƒì„± ì¤‘..."):
        output = agent_executor.invoke({"input": query})["output"]
    st.markdown("**ğŸ“ ì¶”ì²œ ê²°ê³¼**")
    st.write(output)
